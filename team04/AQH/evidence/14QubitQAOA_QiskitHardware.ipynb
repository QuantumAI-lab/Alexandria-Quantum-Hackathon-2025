{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa155a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 binary slack variables per trip\n",
      "Quadratic program created with binary slack variables:\n",
      "Number of variables: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qiskit_runtime_service._resolve_cloud_instances:WARNING:2025-09-12 00:27:34,335: Default instance not set. Searching all available instances.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: ibm_kingston\n",
      "Pending jobs: 12\n",
      "Running QAOA on IBM Quantum hardware with pass_manager...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base_primitive._get_mode_service_backend:WARNING:2025-09-12 00:27:44,734: A backend was passed in as the mode but a session context manager is open so this job will run inside this session/batch instead of in job mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from math import isfinite\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "from qiskit_optimization.minimum_eigensolvers import QAOA\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit import transpile\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, Options, Sampler\n",
    "\n",
    "# -------------------------\n",
    "# Setup evidence collection\n",
    "# -------------------------\n",
    "def setup_evidence_collection():\n",
    "    \"\"\"Create evidence directory structure for challenge submission\"\"\"\n",
    "    evidence_dir = \"evidence\"\n",
    "    logs_dir = os.path.join(evidence_dir, \"logs\")\n",
    "    screenshots_dir = os.path.join(evidence_dir, \"screenshots\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(evidence_dir, exist_ok=True)\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "    os.makedirs(screenshots_dir, exist_ok=True)\n",
    "    \n",
    "    # Create job_ids.csv with header if it doesn't exist\n",
    "    job_ids_file = os.path.join(evidence_dir, \"job_ids.csv\")\n",
    "    if not os.path.exists(job_ids_file):\n",
    "        with open(job_ids_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['timestamp', 'backend', 'job_id', 'mode', 'shots', 'notes'])\n",
    "    \n",
    "    return job_ids_file, logs_dir, screenshots_dir\n",
    "\n",
    "def record_job(job_ids_file, backend_name, job_id, mode, shots, notes=\"\"):\n",
    "    \"\"\"Record a job submission to job_ids.csv\"\"\"\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    with open(job_ids_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([timestamp, backend_name, job_id, mode, shots, notes])\n",
    "    print(f\"Recorded job: {job_id} on {backend_name}\")\n",
    "\n",
    "# Setup evidence collection\n",
    "job_ids_file, logs_dir, screenshots_dir = setup_evidence_collection()\n",
    "\n",
    "# -------------------------\n",
    "# Problem data\n",
    "# -------------------------\n",
    "data = {\n",
    "  \"problem_description\": {\"constraints\": {\"stops_per_trip\": 3}},\n",
    "  \"locations\": {\n",
    "    \"hospital\": {\"name\":\"Central Hospital\",\"coordinates\":{\"latitude\":29.99512653425452,\"longitude\":31.68462840171934}},\n",
    "    \"patients\":[\n",
    "      {\"id\":\"DT\",\"coordinates\":{\"latitude\":30.000417586266437,\"longitude\":31.73960813272627}},\n",
    "      {\"id\":\"GR\",\"coordinates\":{\"latitude\":30.011344405285193,\"longitude\":31.747827362371993}},\n",
    "      {\"id\":\"R2\",\"coordinates\":{\"latitude\":30.030388325206854,\"longitude\":31.669231198639675}},\n",
    "      {\"id\":\"R3_2\",\"coordinates\":{\"latitude\":30.030940768851426,\"longitude\":31.688371339937028}},\n",
    "      {\"id\":\"IT\",\"coordinates\":{\"latitude\":30.01285635906825,\"longitude\":31.693811715848444}}\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "hospital = data[\"locations\"][\"hospital\"][\"coordinates\"]\n",
    "patients = data[\"locations\"][\"patients\"]\n",
    "ids = [p[\"id\"] for p in patients]\n",
    "coord_map = {\"H\": (hospital[\"latitude\"], hospital[\"longitude\"])}\n",
    "for p in patients:\n",
    "    coord_map[p[\"id\"]] = (p[\"coordinates\"][\"latitude\"], p[\"coordinates\"][\"longitude\"])\n",
    "\n",
    "# -------------------------\n",
    "# Distance matrix (using provided data)\n",
    "# -------------------------\n",
    "distance_dict = {\n",
    "    'H': {'H': 0.0, 'DT': 8.6285, 'GR': 11.4958, 'R2': 9.4454, 'R3_2': 10.8524, 'IT': 9.6724},\n",
    "    'DT': {'H': 14.1936, 'DT': 0.0, 'GR': 2.3608, 'R2': 10.922, 'R3_2': 9.238, 'IT': 9.4305},\n",
    "    'GR': {'H': 17.7848, 'DT': 7.7452, 'GR': 0.0, 'R2': 11.8083, 'R3_2': 10.1243, 'IT': 10.478},\n",
    "    'R2': {'H': 11.8644, 'DT': 19.6719, 'GR': 15.6608, 'R2': 0.0, 'R3_2': 11.5718, 'IT': 11.5385},\n",
    "    'R3_2': {'H': 7.3427, 'DT': 12.1719, 'GR': 10.0531, 'R2': 4.0711, 'R3_2': 0.0, 'IT': 5.9308},\n",
    "    'IT': {'H': 9.2692, 'DT': 9.3984, 'GR': 12.2657, 'R2': 7.318, 'R3_2': 8.725, 'IT': 0.0}\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Problem parameters\n",
    "# -------------------------\n",
    "n_trips = 2\n",
    "max_stops = data[\"problem_description\"][\"constraints\"][\"stops_per_trip\"]\n",
    "patients = ids\n",
    "hospital_id = \"H\"\n",
    "\n",
    "# -------------------------\n",
    "# Build QuadraticProgram with assignment formulation and binary slack variables\n",
    "# -------------------------\n",
    "qp = QuadraticProgram()\n",
    "\n",
    "# Create binary variables for each patient-trip assignment\n",
    "for p in patients:\n",
    "    for t in range(1, n_trips + 1):\n",
    "        qp.binary_var(name=f\"x_{p}_{t}\")\n",
    "\n",
    "# Create binary slack variables for capacity constraints\n",
    "slack_bits_per_trip = math.ceil(math.log2(max_stops + 1))\n",
    "print(f\"Using {slack_bits_per_trip} binary slack variables per trip\")\n",
    "\n",
    "for t in range(1, n_trips + 1):\n",
    "    for i in range(slack_bits_per_trip):\n",
    "        qp.binary_var(name=f\"s_{t}_{i}\")\n",
    "\n",
    "# Objective function: minimize total distance\n",
    "linear_terms = {}\n",
    "for p in patients:\n",
    "    for t in range(1, n_trips + 1):\n",
    "        var_name = f\"x_{p}_{t}\"\n",
    "        linear_terms[var_name] = distance_dict[hospital_id][p] + distance_dict[p][hospital_id]\n",
    "\n",
    "# Quadratic terms: distances between patients in the same trip\n",
    "quadratic_terms = {}\n",
    "for t in range(1, n_trips + 1):\n",
    "    for i, p1 in enumerate(patients):\n",
    "        for j, p2 in enumerate(patients):\n",
    "            if i < j:\n",
    "                var1 = f\"x_{p1}_{t}\"\n",
    "                var2 = f\"x_{p2}_{t}\"\n",
    "                quadratic_terms[(var1, var2)] = distance_dict[p1][p2] + distance_dict[p2][p1]\n",
    "\n",
    "# Set the objective\n",
    "qp.minimize(linear=linear_terms, quadratic=quadratic_terms)\n",
    "\n",
    "# Constraints\n",
    "for p in patients:\n",
    "    vars_for_patient = [f\"x_{p}_{t}\" for t in range(1, n_trips + 1)]\n",
    "    coeffs = {var: 1 for var in vars_for_patient}\n",
    "    qp.linear_constraint(linear=coeffs, sense='==', rhs=1, name=f\"assign_{p}\")\n",
    "\n",
    "for t in range(1, n_trips + 1):\n",
    "    vars_for_trip = [f\"x_{p}_{t}\" for p in patients]\n",
    "    slack_vars = [f\"s_{t}_{i}\" for i in range(slack_bits_per_trip)]\n",
    "\n",
    "    coeffs = {var: 1 for var in vars_for_trip}\n",
    "    for i, slack_var in enumerate(slack_vars):\n",
    "        coeffs[slack_var] = 2**i\n",
    "\n",
    "    qp.linear_constraint(linear=coeffs, sense='==', rhs=max_stops, name=f\"capacity_{t}\")\n",
    "\n",
    "print(\"Quadratic program created with binary slack variables:\")\n",
    "print(f\"Number of variables: {qp.get_num_vars()}\")\n",
    "\n",
    "# -------------------------\n",
    "# Setup for IBM Quantum Hardware with pass_manager\n",
    "# -------------------------\n",
    "# Initialize IBM Quantum account (requires prior setup with IBM Quantum token)\n",
    "try:\n",
    "    QiskitRuntimeService.save_account(channel=\"ibm_quantum_platform\" ,token=\"OOwlo7E2TD7cbrxrDlYvzo9vT3RFHHw95QeRgeSwH50i\",overwrite=True)\n",
    "    # Get the least busy backend with enough qubits\n",
    "    service = QiskitRuntimeService()\n",
    "    backends = service.backends(\n",
    "        simulator=False, \n",
    "        operational=True, \n",
    "        min_num_qubits=14\n",
    "    )\n",
    "    \n",
    "    # Sort by least busy\n",
    "    backends_sorted = sorted(backends, key=lambda x: x.status().pending_jobs)\n",
    "    backend = backends_sorted[0]\n",
    "    backend_name = backend.name\n",
    "    print(f\"Using backend: {backend_name}\")\n",
    "    print(f\"Pending jobs: {backend.status().pending_jobs}\")\n",
    "    \n",
    "    # Create a pass manager for the backend\n",
    "    # Use optimization_level=1 to reduce circuit depth while maintaining hardware compatibility\n",
    "    target = backend.target\n",
    "    pm = generate_preset_pass_manager(backend=backend, optimization_level=1)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing IBM Quantum: {e}\")\n",
    "    print(\"Falling back to simulator\")\n",
    "    from qiskit_aer import AerSimulator\n",
    "    backend = AerSimulator()\n",
    "    backend_name = \"aer_simulator\"\n",
    "    # Create a pass manager for the simulator\n",
    "    pm = generate_preset_pass_manager(backend=backend, optimization_level=1)\n",
    "\n",
    "# -------------------------\n",
    "# Configure QAOA for hardware with pass_manager\n",
    "# -------------------------\n",
    "# Track optimization progress\n",
    "loss_history = []\n",
    "\n",
    "def callback(eval_count, parameters, mean, std):\n",
    "    loss_history.append(mean)\n",
    "    print(f\"Iteration {eval_count}: Energy = {mean}\")\n",
    "\n",
    "# Use COBYLA optimizer\n",
    "optimizer = COBYLA(maxiter=50)\n",
    "\n",
    "# Configure QAOA with fewer repetitions to reduce circuit depth\n",
    "reps = 1\n",
    "\n",
    "# Set shots for hardware execution\n",
    "\n",
    "# -------------------------\n",
    "# Solve using Qiskit Runtime with pass_manager\n",
    "# -------------------------\n",
    "print(\"Running QAOA on IBM Quantum hardware with pass_manager...\")\n",
    "t0 = time.time()\n",
    "\n",
    "try:\n",
    "    with Session(backend=backend) as session:\n",
    "        # Create a QAOA instance with pass_manager\n",
    "        qaoa = QAOA(\n",
    "            sampler=Sampler(mode=backend),\n",
    "            optimizer=optimizer,\n",
    "            reps=reps,\n",
    "            initial_point=[0.1, 0.1],  # Good starting parameters\n",
    "            callback=callback,\n",
    "            pass_manager=pm  # Add pass_manager to handle transpilation\n",
    "        )\n",
    "        \n",
    "        # Create optimizer and solve\n",
    "        meo = MinimumEigenOptimizer(qaoa)\n",
    "        result = meo.solve(qp)\n",
    "        \n",
    "      # Record the job ID if running on hardware\n",
    "        if not backend_name.startswith(\"aer_\"):\n",
    "            job_id = None\n",
    "\n",
    "                # ✅ Method 1: Try to get from the sampler’s last job (most reliable)\n",
    "            if hasattr(qaoa.sampler, \"last_job\") and qaoa.sampler.last_job is not None:\n",
    "                try:\n",
    "                    job_id = qaoa.sampler.last_job.job_id()\n",
    "                except Exception as sampler_error:\n",
    "                    print(f\"Could not get job ID from sampler: {sampler_error}\")\n",
    "\n",
    "            # ✅ Method 2: Try to get from result metadata (may work on some backends)\n",
    "            if job_id is None and hasattr(result, \"metadata\") and result.metadata:\n",
    "                try:\n",
    "                    if isinstance(result.metadata, list):\n",
    "                        job_id = result.metadata[0].get(\"job_id\")\n",
    "                    elif isinstance(result.metadata, dict):\n",
    "                        job_id = result.metadata.get(\"job_id\")\n",
    "                except Exception as meta_error:\n",
    "                    print(f\"Could not get job ID from metadata: {meta_error}\")\n",
    "\n",
    "            # Final fallback if all methods fail\n",
    "            if job_id is None:\n",
    "                job_id = \"unknown_job_id\"\n",
    "                print(\"Warning: Could not retrieve job ID from any source\")\n",
    "\n",
    "            # Record the job with the retrieved ID (or fallback)\n",
    "            record_job(job_ids_file, backend_name, job_id, \"physical\", \"QAOA execution\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"plus ultra\")\n",
    "    record_job(job_ids_file, backend_name, \"none\", \"physical\", \"QAOA execution\")\n",
    "\n",
    "    # print(f\"Error with Qiskit Runtime: {e}\")\n",
    "    # print(\"Falling back to local execution with pass_manager\")\n",
    "    \n",
    "    # # Fallback to local execution\n",
    "    # from qiskit_aer.primitives import Sampler as AerSampler\n",
    "    \n",
    "    # qaoa = QAOA(\n",
    "    #     sampler=AerSampler(),\n",
    "    #     optimizer=optimizer,\n",
    "    #     reps=reps,\n",
    "    #     initial_point=[0.1, 0.1],\n",
    "    #     callback=callback,\n",
    "    #     pass_manager=pm  # Use pass_manager for local execution too\n",
    "    # )\n",
    "    \n",
    "    # meo = MinimumEigenOptimizer(qaoa)\n",
    "    # result = meo.solve(qp)\n",
    "\n",
    "t1 = time.time()\n",
    "elapsed = t1 - t0\n",
    "\n",
    "print(f\"Finished in {elapsed:.3f} s. Status: {result.status}\")\n",
    "print(f\"QuadraticProgram objective (raw): {result.fval:.6f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Extract and interpret solution\n",
    "# -------------------------\n",
    "print(\"\\nSolution interpretation:\")\n",
    "print(\"Variable values:\")\n",
    "for var_name, value in result.variables_dict.items():\n",
    "    print(f\"  {var_name}: {value}\")\n",
    "\n",
    "# Extract which patients are assigned to which trips\n",
    "assignments = {}\n",
    "for t in range(1, n_trips + 1):\n",
    "    assignments[t] = []\n",
    "    for p in patients:\n",
    "        var_name = f\"x_{p}_{t}\"\n",
    "        if var_name in result.variables_dict and abs(result.variables_dict[var_name] - 1) < 1e-6:\n",
    "            assignments[t].append(p)\n",
    "\n",
    "# Extract and decode binary slack variables\n",
    "slack_values = {}\n",
    "for t in range(1, n_trips + 1):\n",
    "    slack_binary = 0\n",
    "    for i in range(slack_bits_per_trip):\n",
    "        slack_var = f\"s_{t}_{i}\"\n",
    "        if slack_var in result.variables_dict and abs(result.variables_dict[slack_var] - 1) < 1e-6:\n",
    "            slack_binary += 2**i\n",
    "    slack_values[t] = slack_binary\n",
    "    print(f\"Trip {t} slack (binary decoded): {slack_binary}\")\n",
    "\n",
    "print(\"\\nPatient assignments:\")\n",
    "for t, patients_in_trip in assignments.items():\n",
    "    capacity_used = len(patients_in_trip)\n",
    "    slack_value = slack_values.get(t, 0)\n",
    "    print(f\"Trip {t}: {patients_in_trip} (Capacity used: {capacity_used}/3, Slack: {slack_value})\")\n",
    "    print(f\"  Constraint check: {capacity_used} + {slack_value} = {capacity_used + slack_value} (should be 3)\")\n",
    "\n",
    "# Calculate actual distance for each trip\n",
    "total_distance = 0\n",
    "trip_details = {}\n",
    "for t, patients_in_trip in assignments.items():\n",
    "    if not patients_in_trip:\n",
    "        continue\n",
    "\n",
    "    # Find optimal permutation for this trip\n",
    "    best_perm = None\n",
    "    best_distance = float('inf')\n",
    "\n",
    "    for perm in itertools.permutations(patients_in_trip):\n",
    "        dist = distance_dict[hospital_id][perm[0]]\n",
    "        for i in range(len(perm) - 1):\n",
    "            dist += distance_dict[perm[i]][perm[i+1]]\n",
    "        dist += distance_dict[perm[-1]][hospital_id]\n",
    "\n",
    "        if dist < best_distance:\n",
    "            best_distance = dist\n",
    "            best_perm = perm\n",
    "\n",
    "    total_distance += best_distance\n",
    "    trip_details[t] = {\n",
    "        'patients': best_perm,\n",
    "        'distance': best_distance\n",
    "    }\n",
    "\n",
    "    print(f\"Trip {t} optimal route: H -> {' -> '.join(best_perm)} -> H, Distance: {best_distance:.4f} km\")\n",
    "\n",
    "print(f\"\\nTotal distance: {total_distance:.4f} km\")\n",
    "\n",
    "# Check constraint satisfaction\n",
    "constraints_satisfied = True\n",
    "print(\"\\nConstraint satisfaction check:\")\n",
    "\n",
    "# Check patient assignment constraints\n",
    "for p in patients:\n",
    "    assignment_count = 0\n",
    "    for t in range(1, n_trips + 1):\n",
    "        var_name = f\"x_{p}_{t}\"\n",
    "        if var_name in result.variables_dict and abs(result.variables_dict[var_name] - 1) < 1e-6:\n",
    "            assignment_count += 1\n",
    "    print(f\"Patient {p} assigned to {assignment_count} trips: {'OK' if assignment_count == 1 else 'VIOLATION'}\")\n",
    "    if assignment_count != 1:\n",
    "        constraints_satisfied = False\n",
    "\n",
    "# Check capacity constraints with binary slack\n",
    "for t in range(1, n_trips + 1):\n",
    "    patient_count = 0\n",
    "    for p in patients:\n",
    "        var_name = f\"x_{p}_{t}\"\n",
    "        if var_name in result.variables_dict and abs(result.variables_dict[var_name] - 1) < 1e-6:\n",
    "            patient_count += 1\n",
    "\n",
    "    slack_binary = 0\n",
    "    for i in range(slack_bits_per_trip):\n",
    "        slack_var = f\"s_{t}_{i}\"\n",
    "        if slack_var in result.variables_dict and abs(result.variables_dict[slack_var] - 1) < 1e-6:\n",
    "            slack_binary += 2**i\n",
    "\n",
    "    constraint_value = patient_count + slack_binary\n",
    "    print(f\"Trip {t}: {patient_count} patients + {slack_binary} slack = {constraint_value}: {'OK' if constraint_value == max_stops else 'VIOLATION'}\")\n",
    "    if constraint_value != max_stops:\n",
    "        constraints_satisfied = False\n",
    "\n",
    "print(f\"\\nAll constraints satisfied: {constraints_satisfied}\")\n",
    "\n",
    "# -------------------------\n",
    "# Plot loss curve\n",
    "# -------------------------\n",
    "if loss_history:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history, 'b-', linewidth=1.5)\n",
    "    plt.title('QAOA Optimization Progress')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('qaoa_loss_curve_hardware.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No loss history recorded\")\n",
    "\n",
    "# -------------------------\n",
    "# Create results directory and save outputs\n",
    "# -------------------------\n",
    "results_dir = \"results/physical\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save predictions (patient assignments)\n",
    "with open(os.path.join(results_dir, \"predictions.csv\"), \"w\") as f:\n",
    "    f.write(\"trip,patient,order\\n\")\n",
    "    for t, details in trip_details.items():\n",
    "        for order, patient in enumerate(details['patients'], 1):\n",
    "            f.write(f\"{t},{patient},{order}\\n\")\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------\n",
    "# Save results and manifest (append mode)\n",
    "# -------------------------\n",
    "results_dir = \"results/physical\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Prepare metrics entry\n",
    "metrics_entry = {\n",
    "    \"total_distance\": total_distance,\n",
    "    \"constraints_satisfied\": bool(constraints_satisfied),\n",
    "    \"execution_time\": elapsed,\n",
    "    \"backend\": backend_name,\n",
    "    \"timestamp\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "}\n",
    "\n",
    "# Append to metrics.json\n",
    "metrics_file = os.path.join(results_dir, \"metrics.json\")\n",
    "if os.path.exists(metrics_file):\n",
    "    try:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            existing_metrics = json.load(f)\n",
    "        if not isinstance(existing_metrics, list):\n",
    "            existing_metrics = [existing_metrics]\n",
    "    except Exception:\n",
    "        existing_metrics = []\n",
    "else:\n",
    "    existing_metrics = []\n",
    "existing_metrics.append(metrics_entry)\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    json.dump(existing_metrics, f, indent=2)\n",
    "\n",
    "# Prepare run_summary entry\n",
    "run_summary_entry = {\n",
    "    \"backend\": backend_name,\n",
    "    \"optimizer\": \"COBYLA\",\n",
    "    \"reps\": reps,\n",
    "    \"status\": str(result.status),\n",
    "    \"objective_value\": float(result.fval),\n",
    "    \"constraints_satisfied\": bool(constraints_satisfied),\n",
    "    \"total_distance\": total_distance,\n",
    "    \"execution_time\": elapsed,\n",
    "    \"timestamp\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "}\n",
    "\n",
    "# Append to run_summary.json\n",
    "run_summary_file = os.path.join(results_dir, \"run_summary.json\")\n",
    "if os.path.exists(run_summary_file):\n",
    "    try:\n",
    "        with open(run_summary_file, \"r\") as f:\n",
    "            existing_summary = json.load(f)\n",
    "        if not isinstance(existing_summary, list):\n",
    "            existing_summary = [existing_summary]\n",
    "    except Exception:\n",
    "        existing_summary = []\n",
    "else:\n",
    "    existing_summary = []\n",
    "existing_summary.append(run_summary_entry)\n",
    "with open(run_summary_file, \"w\") as f:\n",
    "    json.dump(existing_summary, f, indent=2)\n",
    "\n",
    "# Prepare manifest entry\n",
    "manifest_entry = {\n",
    "    \"team\": \"Team 4\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"backend\": backend_name,\n",
    "    \"min_qubits\": 14,\n",
    "    \"timestamp\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"artifacts\": {\n",
    "        \"predictions\": \"results/physical/predictions.csv\",\n",
    "        \"metrics\": \"results/physical/metrics.json\",\n",
    "        \"confusion_matrix\": \"results/physical/confusion_matrix.png\",\n",
    "        \"run_summary\": \"results/physical/run_summary.json\"\n",
    "    },\n",
    "    \"evidence\": {\n",
    "        \"job_ids_csv\": job_ids_file,\n",
    "        \"logs_dir\": logs_dir,\n",
    "        \"screenshots_dir\": screenshots_dir\n",
    "    }\n",
    "}\n",
    "\n",
    "manifest_file = \"MANIFEST.json\"\n",
    "if os.path.exists(manifest_file):\n",
    "    try:\n",
    "        with open(manifest_file, \"r\") as f:\n",
    "            existing_manifest = json.load(f)\n",
    "        if not isinstance(existing_manifest, list):\n",
    "            existing_manifest = [existing_manifest]\n",
    "    except Exception:\n",
    "        existing_manifest = []\n",
    "else:\n",
    "    existing_manifest = []\n",
    "existing_manifest.append(manifest_entry)\n",
    "with open(manifest_file, \"w\") as f:\n",
    "    json.dump(existing_manifest, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVIDENCE COLLECTION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ Job IDs recorded in: {job_ids_file}\")\n",
    "print(f\"✓ Results appended in: {results_dir}\")\n",
    "print(\"✓ MANIFEST.json updated (entry appended)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
